{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d070844b",
   "metadata": {},
   "source": [
    "# 3) 바른자세프로젝트 딥러닝모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59adbb",
   "metadata": {},
   "source": [
    "#학습시킨 모델을 불러온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e7532af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                524352    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 15,239,300\n",
      "Trainable params: 524,612\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "model = load_model('./model/20-0.8295.hdf5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b686ab6b",
   "metadata": {},
   "source": [
    "#새로운 이미지를 넣고 딥러닝 모델을 비교하기 위해서 OPENPOSE를 이용해서 스켈레톤을 만든다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cde408fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== BODY_25 Model ==============================\n",
      "[pointed] Nose (0) => prob: 0.87486 / x: 101 / y: 31\n",
      "[pointed] Neck (1) => prob: 0.61511 / x: 101 / y: 74\n",
      "[pointed] RShoulder (2) => prob: 0.50242 / x: 66 / y: 84\n",
      "[pointed] RElbow (3) => prob: 0.73921 / x: 61 / y: 159\n",
      "[pointed] RWrist (4) => prob: 0.73808 / x: 55 / y: 233\n",
      "[pointed] LShoulder (5) => prob: 0.41534 / x: 137 / y: 74\n",
      "[pointed] LElbow (6) => prob: 0.65056 / x: 152 / y: 159\n",
      "[pointed] LWrist (7) => prob: 0.69867 / x: 162 / y: 222\n",
      "[pointed] MidHip (8) => prob: 0.42615 / x: 106 / y: 180\n",
      "[pointed] RHip (9) => prob: 0.37304 / x: 86 / y: 180\n",
      "[pointed] RKnee (10) => prob: 0.60111 / x: 86 / y: 318\n",
      "[pointed] RAnkle (11) => prob: 0.59113 / x: 91 / y: 434\n",
      "[pointed] LHip (12) => prob: 0.37615 / x: 127 / y: 180\n",
      "[pointed] LKnee (13) => prob: 0.66082 / x: 137 / y: 307\n",
      "[pointed] LAnkle (14) => prob: 0.55917 / x: 142 / y: 434\n",
      "[pointed] REye (15) => prob: 0.89886 / x: 96 / y: 21\n",
      "[pointed] LEye (16) => prob: 0.84974 / x: 111 / y: 21\n",
      "[pointed] REar (17) => prob: 0.64987 / x: 81 / y: 21\n",
      "[pointed] LEar (18) => prob: 0.77122 / x: 122 / y: 21\n",
      "[pointed] LBigToe (19) => prob: 0.45997 / x: 162 / y: 456\n",
      "[pointed] LSmallToe (20) => prob: 0.54061 / x: 162 / y: 456\n",
      "[pointed] LHeel (21) => prob: 0.34253 / x: 142 / y: 445\n",
      "[pointed] RBigToe (22) => prob: 0.46780 / x: 76 / y: 445\n",
      "[pointed] RSmallToe (23) => prob: 0.45895 / x: 76 / y: 445\n",
      "[pointed] RHeel (24) => prob: 0.48191 / x: 101 / y: 445\n",
      "[pointed] Background (25) => prob: 1.01174 / x: 96 / y: 286\n",
      "\n",
      "[linked] 0 (101, 31) <=> 1 (101, 74)\n",
      "[linked] 0 (101, 31) <=> 15 (96, 21)\n",
      "[linked] 0 (101, 31) <=> 16 (111, 21)\n",
      "[linked] 1 (101, 74) <=> 2 (66, 84)\n",
      "[linked] 1 (101, 74) <=> 5 (137, 74)\n",
      "[linked] 1 (101, 74) <=> 8 (106, 180)\n",
      "[linked] 8 (106, 180) <=> 9 (86, 180)\n",
      "[linked] 8 (106, 180) <=> 12 (127, 180)\n",
      "[linked] 9 (86, 180) <=> 10 (86, 318)\n",
      "[linked] 12 (127, 180) <=> 13 (137, 307)\n",
      "[linked] 2 (66, 84) <=> 3 (61, 159)\n",
      "[linked] 3 (61, 159) <=> 4 (55, 233)\n",
      "[linked] 5 (137, 74) <=> 6 (152, 159)\n",
      "[linked] 6 (152, 159) <=> 7 (162, 222)\n",
      "[linked] 10 (86, 318) <=> 11 (91, 434)\n",
      "[linked] 13 (137, 307) <=> 14 (142, 434)\n",
      "[linked] 15 (96, 21) <=> 17 (81, 21)\n",
      "[linked] 16 (111, 21) <=> 18 (122, 21)\n",
      "[linked] 14 (142, 434) <=> 21 (142, 445)\n",
      "[linked] 19 (162, 456) <=> 21 (142, 445)\n",
      "[linked] 20 (162, 456) <=> 21 (142, 445)\n",
      "[linked] 11 (91, 434) <=> 24 (101, 445)\n",
      "[linked] 22 (76, 445) <=> 24 (101, 445)\n",
      "[linked] 23 (76, 445) <=> 24 (101, 445)\n",
      "\n",
      "[linked] 0 (101, 31) <=> 1 (101, 74)\n",
      "[linked] 0 (101, 31) <=> 15 (96, 21)\n",
      "[linked] 0 (101, 31) <=> 16 (111, 21)\n",
      "[linked] 1 (101, 74) <=> 2 (66, 84)\n",
      "[linked] 1 (101, 74) <=> 5 (137, 74)\n",
      "[linked] 1 (101, 74) <=> 8 (106, 180)\n",
      "[linked] 8 (106, 180) <=> 9 (86, 180)\n",
      "[linked] 8 (106, 180) <=> 12 (127, 180)\n",
      "[linked] 9 (86, 180) <=> 10 (86, 318)\n",
      "[linked] 12 (127, 180) <=> 13 (137, 307)\n",
      "[linked] 2 (66, 84) <=> 3 (61, 159)\n",
      "[linked] 3 (61, 159) <=> 4 (55, 233)\n",
      "[linked] 5 (137, 74) <=> 6 (152, 159)\n",
      "[linked] 6 (152, 159) <=> 7 (162, 222)\n",
      "[linked] 10 (86, 318) <=> 11 (91, 434)\n",
      "[linked] 13 (137, 307) <=> 14 (142, 434)\n",
      "[linked] 15 (96, 21) <=> 17 (81, 21)\n",
      "[linked] 16 (111, 21) <=> 18 (122, 21)\n",
      "[linked] 14 (142, 434) <=> 21 (142, 445)\n",
      "[linked] 19 (162, 456) <=> 21 (142, 445)\n",
      "[linked] 20 (162, 456) <=> 21 (142, 445)\n",
      "[linked] 11 (91, 434) <=> 24 (101, 445)\n",
      "[linked] 22 (76, 445) <=> 24 (101, 445)\n",
      "[linked] 23 (76, 445) <=> 24 (101, 445)\n"
     ]
    }
   ],
   "source": [
    "# 포인트 찾기\n",
    "def output_keypoints(frame, proto_file, weights_file, threshold, model_name, BODY_PARTS):\n",
    "    global points\n",
    "    # 네트워크 불러오기\n",
    "    net = cv2.dnn.readNetFromCaffe(proto_file, weights_file)\n",
    "\n",
    "    # 입력 이미지의 사이즈 정의\n",
    "    image_height = 368\n",
    "    image_width = 368\n",
    "\n",
    "    # 네트워크에 넣기 위한 전처리\n",
    "    input_blob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (image_width, image_height), (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    # mean: 만약 image의 채널이 BGR 순서이고, swapRB가 true이면 R 평균, G평균, B 평균 순서로 값 지정\n",
    "    # swapRB : 첫 번째 채널과 3번째 채널을 서로 바꿀 것인지를 결정하는 flag.\n",
    "    # 이 값이 true이면 컬러 입력 영상의 채널 순서를 BGR에서 RGB로 변경\n",
    "    # crop : 입력 영상(image)의 크기를 변경한 후, crop을 수행할 것인지를 결정하는 flag\n",
    "    # network입력을 위한 blob으로 변환(blob: 영상 등의 data를 포함할수 있는 다차원 data 표현 방식)\n",
    "    \n",
    "    # 전처리된 blob 네트워크에 입력\n",
    "    net.setInput(input_blob)\n",
    "\n",
    "    # 결과 받아오기\n",
    "    out = net.forward()\n",
    "    out_height = out.shape[2]\n",
    "    out_width = out.shape[3]\n",
    "\n",
    "    # 원본 이미지의 높이, 너비를 받아오기\n",
    "    frame_height, frame_width = frame.shape[:2]\n",
    "\n",
    "    # 포인트 리스트 초기화\n",
    "    points = []\n",
    "\n",
    "    print(f\"\\n============================== {model_name} Model ==============================\")\n",
    "    for i in range(len(BODY_PARTS)):\n",
    "\n",
    "        # 신체 부위의 confidence map\n",
    "        prob_map = out[0, i, :, :]\n",
    "\n",
    "        # 최소값, 최대값, 최소값 위치, 최대값 위치\n",
    "        min_val, prob, min_loc, point = cv2.minMaxLoc(prob_map)\n",
    "\n",
    "        # 원본 이미지에 맞게 포인트 위치 조정\n",
    "        x = (frame_width * point[0]) / out_width\n",
    "        x = int(x)\n",
    "        y = (frame_height * point[1]) / out_height\n",
    "        y = int(y)\n",
    "\n",
    "        if prob > threshold:  # [pointed] \n",
    "            # cv.circle(그림, 중심, 크기, 색상, 두께(-1이면 꽉채움), 선 유형)\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            # cv2.putText(그림, 문구, 시작좌표, 폰트종류, 폰트크기, 색상, 사이즈, 선 유형)\n",
    "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append((x, y))\n",
    "            print(f\"[pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
    "\n",
    "        else:  # [not pointed]\n",
    "            cv2.circle(frame, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frame, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 1, lineType=cv2.LINE_AA)\n",
    "\n",
    "            points.append(None)\n",
    "            print(f\"[not pointed] {BODY_PARTS[i]} ({i}) => prob: {prob:.5f} / x: {x} / y: {y}\")\n",
    "\n",
    "    cv2.imshow(\"Output_Keypoints\", frame)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "# 포인트 선 그리기\n",
    "def output_keypoints_with_lines(frame, POSE_PAIRS):\n",
    "    print()\n",
    "    for pair in POSE_PAIRS:\n",
    "        part_a = pair[0]  # 0 (Head)\n",
    "        part_b = pair[1]  # 1 (Neck)\n",
    "        if points[part_a] and points[part_b]:  # 선 그리기\n",
    "            print(f\"[linked] {part_a} {points[part_a]} <=> {part_b} {points[part_b]}\")\n",
    "            cv2.line(frame, points[part_a], points[part_b], (0, 255, 0), 3)\n",
    "        else:  # 선 그리지 않기\n",
    "            print(f\"[not linked] {part_a} {points[part_a]} <=> {part_b} {points[part_b]}\")\n",
    "\n",
    "    cv2.imshow(\"output_keypoints_with_lines\", frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "# 포인트 선 이미지화\n",
    "def output_lines_image(frame, POSE_PAIRS):\n",
    "    print()\n",
    "    for pair in POSE_PAIRS:\n",
    "        part_a = pair[0]  # 0 (Head)\n",
    "        part_b = pair[1]  # 1 (Neck)\n",
    "\n",
    "        if points[part_a] and points[part_b]:  # 선 그리기\n",
    "            print(f\"[linked] {part_a} {points[part_a]} <=> {part_b} {points[part_b]}\")\n",
    "            cv2.line(frame, points[part_a], points[part_b], (0, 255, 0), 3)\n",
    "        else:  # 선 그리지 않기\n",
    "            print(f\"[not linked] {part_a} {points[part_a]} <=> {part_b} {points[part_b]}\")\n",
    "    cv2.imwrite('testfile.png', frame)   # 테스트 파일 저장\n",
    "    cv2.imshow(\"output_keypoints_with_lines\", frame)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "BODY_PARTS_BODY_25 = {0: \"Nose\", 1: \"Neck\", 2: \"RShoulder\", 3: \"RElbow\", 4: \"RWrist\",\n",
    "                      5: \"LShoulder\", 6: \"LElbow\", 7: \"LWrist\", 8: \"MidHip\", 9: \"RHip\",\n",
    "                      10: \"RKnee\", 11: \"RAnkle\", 12: \"LHip\", 13: \"LKnee\", 14: \"LAnkle\",\n",
    "                      15: \"REye\", 16: \"LEye\", 17: \"REar\", 18: \"LEar\", 19: \"LBigToe\",\n",
    "                      20: \"LSmallToe\", 21: \"LHeel\", 22: \"RBigToe\", 23: \"RSmallToe\", 24: \"RHeel\", 25: \"Background\"}\n",
    "\n",
    "POSE_PAIRS_BODY_25 = [[0, 1], [0, 15], [0, 16], [1, 2], [1, 5], [1, 8], [8, 9], [8, 12], [9, 10], [12, 13], [2, 3],\n",
    "                      [3, 4], [5, 6], [6, 7], [10, 11], [13, 14], [15, 17], [16, 18], [14, 21], [19, 21], [20, 21],\n",
    "                      [11, 24], [22, 24], [23, 24]]\n",
    "\n",
    "# 신경 네트워크의 구조를 지정하는 prototxt 파일 (다양한 계층이 배열되는 방법 등)\n",
    "protoFile_body_25 = \"C:\\\\Users\\\\flors\\\\position\\\\pose_deploy.prototxt\"\n",
    "\n",
    "# 훈련된 모델의 weight 를 저장하는 caffemodel 파일\n",
    "weightsFile_body_25 = weightsFile_body_25 = \"C:\\\\Users\\\\flors\\\\position\\\\pose_iter_584000.caffemodel\"\n",
    "\n",
    "# 이미지 경로\n",
    "test = \"C:\\\\Users\\\\flors\\\\Documents\\\\fotos\\\\25.png\"\n",
    "back = \"C:\\\\Users\\\\flors\\\\position\\\\H.png\"\n",
    "# 키포인트를 저장할 빈 리스트\n",
    "points = []\n",
    "\n",
    "# 이미지 읽어오기\n",
    "frame_body_25 = cv2.imread(test)\n",
    "frame_body = cv2.imread(back)\n",
    "\n",
    "# BODY_25 Model\n",
    "frame_BODY_25 = output_keypoints(frame=frame_body_25, proto_file=protoFile_body_25, weights_file=weightsFile_body_25,\n",
    "                             threshold=0.2, model_name=\"BODY_25\", BODY_PARTS=BODY_PARTS_BODY_25)\n",
    "output_keypoints_with_lines(frame=frame_body_25, POSE_PAIRS=POSE_PAIRS_BODY_25)\n",
    "output_lines_image(frame=frame_body, POSE_PAIRS=POSE_PAIRS_BODY_25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16d17460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(898, 1096, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 선 이미지 파일 확인\n",
    "\n",
    "testfile=\"C:\\\\Users\\\\flors\\\\testfile.png\"\n",
    "testfile= cv2.imread(testfile)\n",
    "plt.imshow(testfile)\n",
    "print(testfile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d55b29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 선 이미지 파일 크기 조정\n",
    "\n",
    "testfile= cv2.resize(testfile.astype('float32'), dsize=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0132d3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 150, 3)\n",
      "(1, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# 선 이미지 파일 shape 조정\n",
    "\n",
    "# testfile= np.expand_dims(testfile, axis=-1)\n",
    "print(testfile.shape)\n",
    "testfile = testfile.reshape(-1,150,150,3).astype('float32')/255\n",
    "print(testfile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "540b76b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자세 상태의 각 확률은  [[0.15203243 0.33363208 0.45040387 0.06393165]]\n",
      "자세 상태는  오다리 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 결과 확인\n",
    "\n",
    "test_predict=list()\n",
    "test_predict.append(model.predict(testfile))\n",
    "\n",
    "print('자세 상태의 각 확률은 ', model.predict(testfile))\n",
    "\n",
    "if test_predict[0].argmax() == 1:  # argmax 확률 높은 거 뽑아냄\n",
    "    text = '바른 자세'\n",
    "    \n",
    "elif test_predict[0].argmax() == 0:\n",
    "    text = '골반 틀어짐'\n",
    "    \n",
    "elif test_predict[0].argmax() == 2:\n",
    "    text = '오다리'\n",
    "\n",
    "elif test_predict[0].argmax() == 3:\n",
    "    text = '어깨 틀어짐'\n",
    "    \n",
    "print('자세 상태는 ', text, '입니다.') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e3e1bd",
   "metadata": {},
   "source": [
    "#전체 이미지에 비해서 부위가 차지하는 부분은 적어 정확도가 떨어짐 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa53e4d2",
   "metadata": {},
   "source": [
    "#정확도를 높이기 위해서 각각의 부위별로 세분화하여 측정하고자 함"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
